{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Знакомство с линейным классификатором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Как выглядит бинарный линейный классификатор? (Фомула для отображения из множества объектов в множество классов)\n",
    "\n",
    "Пусть нам дано множество объектов $X \\in \\mathbb {R} ^ d$, множество классов $ Y \\in \\{ -1, +1 \\}$ (для бинарной классификации) и обучающая выборка $X^l = (x_i, y_i), i = 1 ... l$. Бинарный линейный классификатор выглядит следующим образом:\n",
    "\n",
    "* $a(x, w) = sign(<w, x>+b)$ = $sign(\\sum\\limits_{i=1}^{d} w_ix_i + b)$\n",
    "\n",
    "$w \\in \\mathbb {R} ^ d$ - вектор весов, $b \\in \\mathbb {R}$ - сдвиг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Что такое отступ алгоритма на объекте? Какие выводы можно сделать из знака отступа?\n",
    "\n",
    "* Отступ алгоритма $a(x) = sign(<w, x>)$ на объекте $x_i$ - это величина $M_i = y_i<w, x_i>$.\n",
    "* Можно заметить, что если $M_i < 0$, то алгоритм неправильно классифицирует объект $x_i$, потому что $y_i$ и $<w, x_i>$ разных знаков\n",
    "* Если $M_i > 0$, то алгоритм правильно классифицирует объект $x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Как классификатор вида $a(x) = sign(<w, x>-w_0)$ сводят к классификаторам вида $a(x) = sign(<w, x>)$?\n",
    "\n",
    "Можно добавить в качестве признака константу $x_0 = -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Как выглядит запись функционала эмпирического риска через отступы? Какое значение он дожет принимать для \"наилучшего\" алгоритма классификации?\n",
    "\n",
    "$Q(w, X^l) = \\sum\\limits_{i=1}^{d} I(M_i )\\leq 0) $ - этот функционал показывает, сколько объектов из обучающей выборки было неверно классифицировано. Соответственно наилучший алгоритм классификации должен его минимизировать \n",
    "\n",
    "$I$ - индикаторная функция, её также часто обозначают через $[]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Если в функционале импирического риска (риск с пороговой функцией потерь) всюду написаны строгие наравенства ($M_i < 0$) можете ли вы сражу придумать паамт $w$ для алгоритма классификации $a(x) = sign(<w, x>)$, минимизирующий такой функционал?\n",
    "\n",
    "Да, возьмём вектор весов $w = \\vec 0$, тогда все индикаторы будут равны нулю и это минимизирует функционал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Запишите функционал аппроксимированного эмпирического риска, если выбрана функция потерь $L(M)$\n",
    "\n",
    "$L(M) = log(1+e^{-M})$, тогда \n",
    "* $\\tilde{Q}(w, X^l) = \\sum\\limits_{i=1}^{d} log(1+e^{-M_i})$ -  функционал аппроксимированного эмпирического риска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Что такое функция потерь, зачем она нужна? Как обычно выглядит её график\n",
    "\n",
    "Для того чтобы определить, насколько хорошо работает наш алгоритм, введём понятие $L(a, x) - $ функция потерь (насколько алгоритм $a$ ошибается на $x \\in X$). Она может быть различной, например, для задачи классификации нами уже была рассмотрена функция  $L(a, x_i) = I(M_i < 0) $, которая показывает, ошибся ли алгоритм $a$ на входе $x_i$. \n",
    "\n",
    "Алгоритм робатает хорошо, если функция потерь на каждом объекте принимает маленькие значения, таким образом, чтобы подобрать параметры алгоритма, нужно минимизировать функцию потерь, но рассмотренная выше функция не является дифференцируемой, поэтому мы не сможем применить градиентные методы оптимизации. Для того чтобы их можно были применить функцию потерь оценивают сверху гладкой функцией. График функции потерь приближает ступенчатую сверху"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"http://vignette2.wikia.nocookie.net/learnmachinelearning/images/0/03/%D0%9D%D0%B5%D0%BF%D1%80%D0%B5%D1%80%D1%8B%D0%B2%D0%BD%D1%8B%D0%B5_%D0%B0%D0%BF%D0%BF%D1%80%D0%BE%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D1%86%D0%B8%D0%B8.png/revision/latest/scale-to-width-down/691?cb=20170104144714&path-prefix=ru\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.  Приведите пример негладкой фунеции потерь\n",
    "\n",
    "Например, Hinge Loss\n",
    "  * $ L(x, y; w) = max(0, 1 - y<w, x>)$\n",
    "  \n",
    "Или ступенчатая функция потерь\n",
    "  * $L(x_i, y_i; w) = [M_i <0 ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Что такое регуляризация? Какие регуляризаторы вы знаете?\n",
    "\n",
    "Как известно, алгоритмы могут переобучаться, одним из признаков переобучения линейных классификаторов являются слишком большие веса некоторых признаков. Это плохо, потому что алгоритм становится излише чувствителен к некоторым признакам объекта, и при малом изменении одного из признаков с большим весом, ответ алгоритма может координально поменяться, это и означает, что мы переобучились.\n",
    "\n",
    "Для борьбы переобучением к функционалу риска прибавляют регуляризатор \n",
    "\n",
    "$Q_{\\tau}(w) = Q(w) + \\tau R(w)$, где $R(w)$ - это регуляризатор\n",
    "\n",
    "Наиболее распространенные регуляризаторы -это $L_1$ и $L_2$ регуляризаторы:\n",
    "* $L_1 = \\sum\\limits_{i = 1}^{d} |w_i|$\n",
    "* $L_2 = \\sum\\limits_{i = 1}^{d} w_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Как связаны переобучение и обобщающая способность алгоритма? Как влияет регуляризация на обобщающую спасобность?\n",
    "Алгоритм называется переобученным, если он слишком подстраивается под обучающую выборку, но не открывает общей закономерности. Таким образом, чем больше алгоритм переобучен, тем меньше его обобщающая способность. Регуляризация позволялет избежать проблемы переобучения, поскольку она контролирует выбор параметров, настраиваемых алгоритмом. \n",
    "\n",
    "Чем меньше константа регуляризации, тем больше свободы мы даём алгоритму в настройке параметров, тем больше шансов переобучиться, то есть у алгоритма будет низкая обобщающая способнотсь. Однако если константа регуляризации слишком большая, то возникает риск недообучиться, так как алгоритм не сможет подобрать подходяшие параметры. Таким образом, константа регуляризации - это гиперпараметр алгоритма, который нужно настраивать \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 11. Как связаны острые минимумы функционала аппроксимированного эмпирического риска с проблемой переобучения?\n",
    "\n",
    "Скорее всего, если мы находимся в остром минимуму, то мы переобучились\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Что делает регуляризация с аппроксимированным риском как функцией параметров алгоритма?\n",
    "\n",
    "Регуляризиция добавляется к функции аппроксиморованного риска, то есть увеличивает её значение. Таким образом, возникает потребность минимизировать не только ошибку алгоритма на объектах обучающей выборки, но и веса признаков. Те есть мы штрафуем нашу модель за слишком большие веса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Для какого алгоритма классификации функционал аппроксимированного риска будет принимать большее значение на обучающей выборке: для построенного с регуляризацией или без нее? Почему?\n",
    "\n",
    "Функционал аппроксимированного риска будет принимать большее значение на обучающей выборке для алгоритма классификации, построенного с регуляризацией. Без регуляризации алгоритм будет стараться подобрать идеальные параметры для обучающей выборки, те он будет максимально подстраивать параметры под обучающую выборку так, чтобы риск был минимален. Регуляризация же будет препятствовать такой подгонке, так что риск алгоритма с регуляризацией на обучающей выборке будет больше\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Для какого алгоритма классификации функционал риска будет принимать большее значение на тестовой выборке: для построенного с оправдывающей себя регуляризацией или вообще без нее? Почему?\n",
    "\n",
    "Всё зависит от данных, но в целом, функционал риска будет принимать большее значение на тестовой выборке для алгоритма, построенного без регуляризации, потому что скорее всего он идеально  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Что представляют собой метрики качества Accuracy, Precision и Recall?\n",
    "\n",
    "* Accuracy определяяет долю правильных ответов алгоритма. Пусть у нас есть алгоритм $a(x)$, размер выборки $N$, тогда точность определяется фомулой:\n",
    "$$ Accuracy = \\frac{\\sum\\limits_{i = 1}^{N}[a(x_i)=y_i]}{l}$$\n",
    "\n",
    "Построим далее матрицу ошибок \n",
    "<img src=\"https://docs.microsoft.com/ru-ru/azure/machine-learning/media/machine-learning-evaluate-model-performance/6a.png\">\n",
    "\n",
    "Колнки показывают значения, предсказанные алгоритмом, а строки - действительное значение класса на данном объекте. Тогда можно ввести следующие метрики качества\n",
    "\n",
    "* Precision - точность, она показывает, сколько объектов, которые алгоритм отнёс к классу положителных объектов, действительно является положительными\n",
    "$$ Presicion = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "* Recall - полнота. Показывает, сколько положительных объектов их всех положительных объектов алгоритм классифицирует правильно. Это отношение правильно классифицированных положительных объектов к числу пропусков, те объектов, которые принадлежат классу $+1$, но наш алгоритм классифицировал его неправильно\n",
    "$$Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Что такое метрика качества AUC и ROC-кривая?\n",
    "\n",
    "\n",
    "Отложим по оси $X$ долю ложных срабатываний (false positive rate): $FPR = \\frac{FP}{FP+TN}$\n",
    "\n",
    "По оси $Y$ долю верных срабатываний (true positive rate): $TPR = \\frac{TP}{TP+FN}$\n",
    "\n",
    "Тогда $ROC$ кривая строится по точкам $TPR$ и $FPR$\n",
    "\n",
    "$AUC$ - это площать под $ROC$ кривой\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  17. Как построить ROC-кривую (нужен алгоритм), если например, у вас есть правильные ответы к домашнему заданию про фамилии и ваши прогнозы?\n",
    "\n",
    "Строим $ROC$ кривую по следующему алгоритму:\n",
    "\n",
    "- Сортируем выборку $X^l$ по убыванию ответов $a(x_i)$.\n",
    "\n",
    "- Отмечаем точку $(FPR_0, TPR_0) = (0, 0)$ .\n",
    "\n",
    "- Посчитаем колчество фамилий и не фамилий в выборке $m+$ и $m-$\n",
    "\n",
    "- $\\forall i \\in {1..l}$:\n",
    "     * если $y_i = -1$, то $FPR_i = FPR_{i - 1} + \\frac{1}{m_-}$, $TPR_i = TPR_{i - 1}$,\n",
    "\n",
    "     * иначе - $FPR_i = FPR_{i - 1}$, $TPR_i = TPR_{i - 1} + \\frac{1}{m_+}$ .\n",
    "     \n",
    "     * отмечаем точку ($FPR_i, TPR_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Вероятностный смысл регуляризаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Покажите, что регуляризатор в задаче линейной классификации имеет вероятностный смысл априорного распределения параметров моделей. Какие распределения задают l1-регуляризатор и l2-регуляризатор?\n",
    "\n",
    "* Пусть для параматерической модели задана плотность распределения  $p(x,y|\\omega)$, также задана априорная плотность распределения параметров модели $p(\\omega)$. Распишем совместное распределение выборки $X^l$ и параметров рапределения $\\omega$ по формуле условной вероятности: $$p(X^l, \\omega) = p(X^l | \\omega)p(\\omega)$$ - функция правдоподобия. Распишем логорифм функции правдоподобия: $$L(X^l, \\omega) = \\sum\\limits_{i = 1}^{l}ln \\space p(x_i, y_i|\\omega) + ln\\space p(\\omega)$$ Таким образом, слагаемое $ln\\space p(\\omega)$ можно рассматривать как регуляризатор\n",
    "\n",
    "* При $l1$ регуляризаторе априорное распределение параметров - распределение Лапласа с плотностью $p(\\omega) = \\frac{1}{(2C)^n} e^{-\\frac{1}{C}\\sum\\limits_{i = 1}^{l} |\\omega_i|}$. Действительно, возьмем логарифм плотности: $ln\\space p(\\omega) = -\\frac{1}{C} \\sum\\limits_{i = 1}^{l} |\\omega_i| + const$, что и требовалось\n",
    "\n",
    "*  При $l2$ регуляризаторе априорное распределение параметров - нормальное распределение с плотностью $p(\\omega) = \\frac{1}{(2 \\pi \\sigma)^{n / 2}} e^{-\\frac{1}{2 \\sigma}\\sum\\limits_{i = 1}^{l} \\omega_i^2}$. Логарифм плотности: $ln\\space p(\\omega) = -\\frac{1}{2 \\sigma} \\sum\\limits_{i = 1}^{l} \\omega_i^2 + const$. Причём компоненты вектора $\\omega$ независимы и имеют нормальное распределение с нулевым матожидание в дисперсией $\\sigma$\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.3 SVM и максимизация разделяющей полосы\n",
    "####  Покажите, как получается условная оптимизационная задача, решаемая в SVM из соображений максимизации разделяющей полосы между классами. Можно отталкиваться от линейно разделимого случая, но итоговое выражение должно быть для общего. Как эта задача сводится к безусловной задаче оптимизации?\n",
    "\n",
    "Пусть у нас есть классификатор $a(x) = sign<w,x>+b$\n",
    "\n",
    "* Рассмотрим сначала линейно разделимый случай.\n",
    "То есть существуют $w_0, b_0$, что классификатор не сделает ни одной ошибки на обучающей выборке. Если одновременно умножить $w, b$ на одну и туж де полоижтельную константу, то ответ классификатора не изменится, потому что классификатору важен лишь знак выражения, а домножение на положительную константу знак не меняет, так что можем нормировать параметры так, чтобы $$ \\min_{x \\in X^l}|<w,x> + b| = 1$$ Расстояние от точки $x_0$ до гиперплоскости, которую отсекает классификатор, равно: $$\\rho(x_0, a) = \\frac{|<w, x_0>+b|}{||w||}$$ Тогда расстояние до гиперплоски от самого ближайшего объекта обучающей выборки равно $$\\min_{x \\in X^l} \\frac{|<w, x>+b|}{||w||} = \\frac{1}{||w||}\\min_{x \\in X^l} |<w, x>+b| = \\frac{1}{||w||} $$ Таким образом, ширина разделяющей полосы равна $\\frac{2}{||w||}$. Так как максимизация разделяющей полосы приводит к повышению обобщающей способности алгоритма, то мы получаем следующую задачу оптимизации\n",
    "\n",
    "$$\\frac{2}{||w||} \\to max$$ и $$ y_i (<w, x_i> +b) \\ge 1, \\  i= 1...l$$\n",
    "\n",
    "* Перейдём к неразделимому случаю.\n",
    "\n",
    "Пусть теперь существует $ x_i \\in X^l : y_i(<w, x_i>+b) < 1$. Введём штраф за попадание за разделяющую полосу $$y_i(<w, x_i>+b) \\geq 1 - \\xi_i,\\space \\xi_i \\ge 0, \\space i = 1, ..., l$$ \n",
    "\n",
    "Получим следующую оптимизационную задачу:\n",
    "\n",
    "$\\frac{1}{2} ||w||^2 + C \\ \\sum\\limits_{i = 1}^{l} \\xi_i \\to \\min_{w, b, \\xi}$\n",
    "\n",
    "$y_i (<w, x_i> +b) \\ge 1 - \\xi_i, \\space i = 1, ..., l$,\n",
    "\n",
    "$\\xi_i \\ge 0, \\space i = 1, ..., l$\n",
    "\n",
    "\n",
    "* Сведём к задаче безусловной оптимизации\n",
    "\n",
    "$M_i = y_i (<w, x_i> +b)$ - отступ на i-м объекте. Тогда из третьего условия $\\xi_i \\ge 0$, из второго условия $\\xi_i \\ge 1 - M_i$ и из первого $\\sum\\limits_{i = 1}^{l} \\xi_i \\to min$, откуда следует $\\xi_i = \\max(0, 1 - M_i) = (1 - M_i)_+$.\n",
    "\n",
    "Итого $Q(w, b) = C\\sum\\limits_{i = 1}^{l} (1 - M_i(w, b))_+ + \\frac{1}{2} ||w||^2 \\to \\min_{w, b}$ - задача безусловной оптимизации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Kernel trick\n",
    "#### Придумайте ядро, которое позволит линейному классификатору с помощью Kernel Trick построить в исходном пространстве признаков разделяющую поверхность $x_1^2 + 2x_2^2 = 3$. Какой будет размерность спрямляющего пространства?\n",
    "\n",
    "Рассмотрим полиномиальное ядро $K(u, v) = (u, v)^2 = <(u_1^2, u_2^2, \\sqrt{2}u_1u_2), (v_1^2, v_2^2, \\sqrt{2}v_1v_2)>$\n",
    "\n",
    "Так как $K(u, v) = <\\psi(u), \\psi(v)>$, значит $\\psi:\\mathbb {R} ^ 2 \\to \\mathbb {R} ^ 3$ определена по правилу $\\psi(u_1, u_2) = (u_1^2, u_2^2, \\sqrt{2}u_1u_2)$\n",
    "\n",
    "Тогда линейная поверхность в спрямляющем пространстве будет иметь вид $<(u_1^2, u_2^2, \\sqrt{2}u_1u_2), (w_1, w_2, w_3)> + w_0 =  w_1u_1^2+ w_2u_2^2+ w_3\\sqrt{2}u_1u_2 + w_0$, при $w = (1,2, 0), w_0 = -3$ получаем то, что требовалось в условии \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.5 $l_1$-регуляризация\n",
    "#### Покажите с помощью теоремы Куна-Таккера, что ограничение $l_1$-нормы вектора весов числом и добавление штрафа с его $l_1$-нормой приводят к построению одного и того же алгоритма. Можно считать, что регуляризатор добавляется по существу, т.е. меняет итоговый ответ по сравнению с оптимизационной задачей без регуляризатора.\n",
    "\n",
    "Обозначим $L$ - функция потерь алгоритма\n",
    "\n",
    "Докажем, что следующие задачи эквивалентны:\n",
    "\n",
    "(1) $\\sum \\limits_{i = 1}^{l} L(M_i) \\to \\min$ и $\\sum \\limits_{i = 1}^{l} |w_i| \\leq C$\n",
    "\n",
    "(2)  $\\sum \\limits_{i = 1}^{l} L(M_i) + \\lambda \\sum \\limits_{i = 1}^{l} |w_i| \\to \\min$\n",
    "\n",
    "Лагранжиан системы (1): $L(w, \\lambda) = \\sum \\limits_{i = 1}^{l} L(M_i) + \\lambda \\left( \\sum \\limits_{i = 1}^{l} |w_i|-C \\right)$. По теореме Куна-Таккера для существования решения $w^*$ в (1) необходимо и достаточно существования такой $\\lambda \\ge 0 :$\n",
    "1. $L(w^*, \\lambda) = \\min_{w}L(w, \\lambda)$\n",
    "2. $\\lambda \\left(  \\sum \\limits_{i = 1}^{l} |w_i|-C \\right)=0$\n",
    "\n",
    "Для достаточности условий 1. и 2. необходимо также условие Слейтера, то есть существования $w: \\sum \\limits_{i = 1}^{l} |w_i| < C$, но это выполнени при $C>0$. Значит, (2) $<=>$ 1. Посмотрим на выполнение условия 2. Разберём случаи:\n",
    "* При $\\lambda = 0$ оптимальная точка лежит внутри области  $\\sum \\limits_{i = 1}^{l} |w_i| < C$, значит ограничение $\\sum \\limits_{i = 1}^{l} |w_i| \\leq C$ является излишним и задача (1) переходит в задачу оптимизации без ограничений, а это эквивалентно (2) при $\\lambda = 0$\n",
    "\n",
    "* Пусть $\\sum \\limits_{i = 1}^{l} |w_i|=C$, этого можно добиться в задаче (2), обозначив через $C$ значение нормы весов, оптимальных с точки зрения задачи (2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.6 Повторение: метрики качества\n",
    "#### 1. Что представляют собой метрики качества Accuracy, Precision и Recall?\n",
    "#### 2. Что такое метрика качества AUC и ROC-кривая?\n",
    "#### 3. Как построить ROC-кривую (нужен алгоритм), если например, у вас есть правильные ответы к домашнему заданию про фамилии и ваши прогнозы?\n",
    "\n",
    "Ответы в разделе 3.1 вопросы 15, 16, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
