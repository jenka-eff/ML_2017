{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Questions (0.5 балла)\n",
    "##### Вопрос 1: Объясните, чем отличается k-nearrest Neighbours от k-weighted nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В  k-nearrest Neighbours мы не учитываем расстояние от нашего объекта до его соседей, этот метод более подвержен неоднозначности классификации. Т.е пусть у нас k=2, первый сосед относится к классу 2 и находится ближе к объекту, который мы хотим классифицировать, а второй сосед относится к классу 1 и находится подальше. Тогда  k-nearrest Neighbours выдаст коллизию, а k-weighted nearest neighbours покажет, что наш объект принадлежит второму классу, потому что первый сосед находится ближе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 2: Как изменяется абсолютное расстояние между объектами выборки при изменении метрики минковского с $p=1$ до  $p=\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rho_1(x, y) = \\sum\\limits_{i=1}^{d} |x_i - y_i|$\n",
    "\n",
    "$\\rho_{\\infty}(x, y) = max_{i=1 ... d} |x_i - y_i|$\n",
    "\n",
    "при $p=1$ расстояние между объектами будет больше, чем при $p = \\infty$, тк $max_{i=1 ... d} |x_i - y_i| \\leq \\sum\\limits_{i=1}^{d} |x_i - y_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 3: Поясните, в чем суть проклятия размерности?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При росте размерности объекты становятся более удаленными друг от друга, т.е например чтобы с большой вероятностью найти несколько ближайших соседей точки $(0,0,...0)$ среди равномерно распределенных точек в $d$-мерном кубе со стороной $[0; 1]$ нужно отступать на расстояния, быстро растущие с ростом $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 4: Что такое метрический отступ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть объект $ u \\in X$. Введём понятие функции близости  $u$ к объектам класса $y \\in Y$: $\\Gamma_y(u)$ - просто складывает все объекты из класса $y$ с их весами относительно $u$. А теперь на основе этой функции построим классификатор, который объекту сопоставляет класс с наибольший функцией близости:\n",
    "\n",
    "Теперь оценим, насколько объект обучающей выборки \"близок\" своему классу. Для объекта $x_i$ мы знаем, к какому классу он принадлежит - $y_i$, проверим, насколько хорошо наш объект подходит под свой класс:\n",
    "\n",
    "$M(x_i) = Г_{y_i}(x_i)  - max_{y \\in Y \\backslash y_i} Г_y(x_i)$ - мы взяли суммарный вес относительно $x_i$ всех объетов из класса $y_i$ и вычли максимальный вес объектов из другого класса, это называется метрический отступ. Чем больше эта величина, тем лучше объект подходит под свой класс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 5: На какие типы можно разделить объекты обучающей выборки с точки значения значения метрического отступа? Какие объекты стоит исключить из выборки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого объекта выборки оценим величину отступа, и отсортируем по этой величине. Получим пять условных классов объектов\n",
    "\n",
    "Эталонные - объекты, которые хорошо подходят под свой класс, имеют большой положительный отступ. Можно брать за основу для классификации\n",
    "\n",
    "Неинформативные - объекты, которые тоже имеют положительный отступ, но не добавляют никакой дополнительной информации к эталонным объектам. Наличие объектов такого класса характерно для избыточной выборки\n",
    "\n",
    "Пограничные - с почти нулевым отступом, классификация таких объектов может измениться при изменении метрики или других каких-то параметров\n",
    "\n",
    "Ошибочные - неверно классифицированные объекты. Ошибка может быть допущена из-за неудачного выбора модели\n",
    "\n",
    "Шумовые объекты или выбросы - с большим отрицательным отступом. Т.е они окружены объектами другого класса. Такие объекты следует исключать из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 6: Что такое функционал эмпирического риска? Приведите примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы определить, насколько хорошо работает наш алгоритм, введём понятие $L(a, x) - $ функция потерь (насколько алгоритм $a$ ошибается на $x \\in X$).\n",
    "\n",
    "Она может быть разной в зависимости от задачи:\n",
    "\n",
    "$L(a, x) = I(x) $ - индикаторная функция, подходит для задач классификации.\n",
    "\n",
    "$L(a, x) = |a(x) - y(x)| $ - показывает, на сколько ответ алгоритма отличается от настоящего. Для задачи регрессии.\n",
    "\n",
    "А теперь усредним все \"потери\", получится эмпирическая функция риска:\n",
    "\n",
    "$Q(a, X^{l}) = \\frac{1}{l}\\sum\\limits_{i=1}^l L(a, x_{i})$ - таким образом, этот функционал показывает, насколько хорошо работает алгоритм на всей обучающей выборке. Нужно подобрать такой алгоритм $a$, чтобы значение функционала было как можно меньше \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 7: В чём суть явления переобучения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явление переобучения состоит в том, что наш алгоритм слишком подстроился под обучающую выборку, но не открыл общей закономерности. Или, что то же самое, эмпирическая функция мала на данных из обучающей выборки, но на контрольной выборке принимает большие значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 8: Напишите формулу для complete cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Суть метода complete cross validation состоит в том, чтобы разбить всю нашу выборку размера $L$ на части размера $l$ всеми способами, т.е $ N = C^{l}_{L}$, $X = X^{l}_{n} \\cup X^{k}_{n}, n \\in \\{ 1 ... N\\}, k = L-l$. Для каждого $ n \\in \\{ 1 ... N\\}$ обучим алгоритм $ a $ на обучающей выборке $X^{l}_{n}$, проверим на контрольной $X^{k}_{n}$ и усредним ошибку по всем элементам из контрольной выборки, а теперь усредним значения по всем разбиениям:\n",
    "\n",
    "$CCV(\\mu, X^{L}) =\\frac{1}{N}\\sum\\limits_{n=1}^N \\frac{1}{k} \\sum\\limits_{x_i \\in X^{k}_{n}} I\\{a(x_i, X^{l}_{n}) \\neq y_i\\}$ - это будет оценка качества нашего алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задача 1 (0.5 балла)\n",
    "###### При каких значения параметра $k$ (при близких к единице или при сильно больших единицы) в алгоритме kNN можно наблюдать эффект переобучения? Поясните свой ответ, опираясь на границы классов из sklearn-knn-surfaces.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $k$ близких к 1 наблюдается эффект переобучения, это видно, потому что синие точки при $ k = 1, 2$ попадают в красную область, потому что поблизости находится одна красная точечка, а если посмотреть на большее количество соседей, то видно, что точки должны быть синими "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализуйте kNN (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from scipy.spatial.distance import cosine, euclidean, minkowski\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class kNNClassifier():\n",
    "    def __init__(self, n_estimators, metric):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_neighbours: int\n",
    "            Число соседей\n",
    "\n",
    "        metric: *alias\n",
    "            метрика измерения расстояний\n",
    "\n",
    "          \"\"\"\n",
    "        self.n_neighbours = n_estimators\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array\n",
    "        y: 1d np.array\n",
    "        \"\"\"\n",
    "\n",
    "        # Тут храните описание объектов обучающей выборки\n",
    "        self.X_learn = X\n",
    "\n",
    "        # Тут храните здесь ответы по каждому объекту обучающей выборки\n",
    "        self.y_learn = y\n",
    "        \n",
    "        # будем также хранить количество классов\n",
    "        self.num_classes = len(set(y))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array матрица объекты признаки на которых нужно сказать ответ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: 1d np.array, Вектор классов для каждого объекта\n",
    "        \"\"\"\n",
    "        \n",
    "        dist = [] # Храните тут расстояния до каждого элемента обучающей выборки \n",
    "        \n",
    "        # количество ближайших соседей из каждого класса для каждого элемента X \n",
    "        neigh = np.zeros((X.shape[0], self.num_classes)) \n",
    "        \n",
    "        for j in range(X.shape[0]):\n",
    "            dist.append([])\n",
    "            for i in range(self.X_learn.shape[0]):\n",
    "                # =======================================\n",
    "                # рассчитайте расстояние до каждого объекта обучающей выборки\n",
    "                # ======================================\n",
    "                \n",
    "                # добавляем пару - расстояние, класс\n",
    "                dist[j].append((self.metric(self.X_learn[i], X[j]), self.y_learn[i])) \n",
    "                \n",
    "            # сортируем по расстоянию\n",
    "            dist[j].sort()\n",
    "            \n",
    "            # выбираем первые n_neighbours соседей\n",
    "            dist[j] = dist[j][:self.n_neighbours]\n",
    "            \n",
    "            # считаем, сколько ближайших соседей из каждого класса имеет объект (dist[obj][train_obj][1] содержит класс)\n",
    "            for i in range(self.n_neighbours):\n",
    "                neigh[j][dist[j][i][1]] += 1\n",
    "            \n",
    "        \n",
    "        # =======================================\n",
    "        # предскажите класс каждого из объектов\n",
    "        # =======================================\n",
    "        y_pred = [ np.argmax(neigh[i]) for i in range(X.shape[0])]\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Запустите ваш алгоритм на данных Digit_recognizer\n",
    "\n",
    "train = pd.read_csv('data/digit_recognizer/train.csv')\n",
    "\n",
    "indices = list(range(train.shape[0]))\n",
    "shuffle(indices)\n",
    "\n",
    "# уменьшила значения, потому что очень долго считает\n",
    "subtrain, subtest = train.ix[indices[:500]], train.ix[indices[500:1000]]\n",
    "\n",
    "X_train, X_test= np.asarray(subtrain[list(range(1, train.shape[1]))]), np.asarray(subtest[list(range(1, train.shape[1]))])\n",
    "Y_train, Y_test = np.asarray(subtrain[[0]]).ravel(), np.asarray(subtest[[0]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# =======================================\n",
    "# Обучите классификатор при k=3, 5, и 10\n",
    "# ======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 accuracy on train data  0.924  accuracy on test data  0.822\n"
     ]
    }
   ],
   "source": [
    "clf = kNNClassifier(3, euclidean)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"k = 3 \" + \"accuracy on train data \", accuracy_score(clf.predict(X_train), Y_train), \" accuracy on test data \",\n",
    "      accuracy_score(clf.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 accuracy on train data  0.908  accuracy on test data  0.812\n"
     ]
    }
   ],
   "source": [
    "clf = kNNClassifier(5, euclidean)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"k = 5 \" + \"accuracy on train data \", accuracy_score(clf.predict(X_train), Y_train), \" accuracy on test data \",\n",
    "      accuracy_score(clf.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 accuracy on train data  0.878  accuracy on test data  0.772\n"
     ]
    }
   ],
   "source": [
    "clf = kNNClassifier(10, euclidean)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"k = 10 \" + \"accuracy on train data \", accuracy_score(clf.predict(X_train), Y_train), \" accuracy on test data \",\n",
    "      accuracy_score(clf.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация (2 балла)\n",
    "Зависимость значения CV от размера тестовой выборки.\n",
    "\n",
    "\n",
    "Продемонстрируйте экспериментально, как меняется значения $CV$ в зависимости от $k$ - количество объектов в тестовой выборке, если объём всех данных меняется и равен $l+k$ (т.е. количество объектов в обучающей выборке НЕ меняется).\n",
    "Размер обучающей выборки $l$ взять таким, чтобы можно было посчитать значения $CV$ при $k=10\\cdot l$. Демонстрацию провести на данных из соревнования Digit Recognizer на Kaggle.\n",
    "В качестве алгоритма классификации можно взять sklearn.neighbors.KNeighborsClassifier(algorithm='ball\\_tree')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 900\n",
    "subtrain = train.ix[indices[:l]]\n",
    "\n",
    "X_train = np.asarray(subtrain[list(range(1, train.shape[1]))])\n",
    "Y_train = np.asarray(subtrain[[0]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = [int(0.3*l), int(0.5*l), l, 3*l, 5*l, 7*l, 10*l]\n",
    "\n",
    "estimator = KNeighborsClassifier(algorithm='ball_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=270 scoring.mean() 0.874 scoring.std() 0.0057\n",
      "k=450 scoring.mean() 0.871 scoring.std() 0.0121\n",
      "k=900 scoring.mean() 0.865 scoring.std() 0.0079\n",
      "k=2700 scoring.mean() 0.869 scoring.std() 0.0072\n",
      "k=4500 scoring.mean() 0.874 scoring.std() 0.0072\n",
      "k=6300 scoring.mean() 0.868 scoring.std() 0.0047\n",
      "k=9000 scoring.mean() 0.867 scoring.std() 0.0061\n"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "    \n",
    "    # Реализуем кросс валидацию\n",
    "    scoring = []\n",
    "    for i in range(5):\n",
    "        indices = np.arange(0, train.shape[0])\n",
    "        shuffle(indices)\n",
    "\n",
    "        subtrain, subtest = train.ix[indices[:l]], train.ix[indices[l:(l+k)]]\n",
    "        X_train, X_test= np.asarray(subtrain[np.arange(1, train.shape[1])]), np.asarray(subtest[np.arange(1, train.shape[1])])\n",
    "        Y_train, Y_test = np.asarray(subtrain[[0]]).ravel(), np.asarray(subtest[[0]]).ravel()\n",
    "        \n",
    "        estimator.fit(X_train, Y_train)    \n",
    "        \n",
    "        score = estimator.score(X_test, Y_test)\n",
    "        scoring.append(score)\n",
    "    \n",
    "    scoring = np.array(scoring)\n",
    "    print(\"k=\" + str(k) + \" scoring.mean()\", '%.3lf' % scoring.mean(), \"scoring.std() \"'%.4lf' % scoring.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: После проведения нескольких экспериметов выяснилось, что значения среднего примерно одинаковые и не зависят от размеров тестовой выборки, а дисперсия уменьшается и далее стабилизируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
